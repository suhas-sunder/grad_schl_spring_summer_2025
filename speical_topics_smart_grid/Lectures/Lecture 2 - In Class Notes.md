### North American Power System
- With traditional power generation, we have a large generation system and power flows through the loads. North American power systems are interconnected.
- Production in USA is much higher with around 4,055 Terra Watt Hours. Canada was only 500ish.
- Lots of interconnection between US and Canada. We are better connected North/South vs East/West.'
- There is now a push to go East/West that is being talked about.
- Import and export of power between US and Canada. Manitoba, Ontario, etc. export a large amount. BC, AB, SK, etc. import more than export.
- NERC background knowledge: Covered in slides
	- Very strict rules and trade agreements that need to be followed and maintained. There are eight reliability entities within the system which looks at the reliability within each area (8 areas), which is then reported to NERC. 
	- NPCC, FRCC, ERCOT, RFC, MRO, WECC, SERC, SPP, ASCC
- Hdro Quebec sits on its own. It is not synchronized because it only has DC lines going, so it is asynchronously connected to NPCC.
- Similarly, ERCOT connected via dc lines. Same with quebec and alberta. They are not synchronoized so they need DC connection.
- 26 lines going into US.
- IESO manages the market and also makes sure the system is reliably operated. So it manages the settlements and financial operations of $13 Billion wholesale market.

### Protection Basics
- Before smart grid started, we had protection monitoring control, but not at the same level as Smart Grid, but some portions were there. Some data coule be transfered beetween devices because there was some communication. So that date could be taken to management and transaction processing. Not really like smart grid but still somewhat capable. SOme of that data could be taken do design and analysis too. Again, not at the same level as Smart Grid but some aspects were there. The main emphasis was on these digital devices that could do protection, monitoring and control. Those are the devices we'll be talking mostly on this course which can be linked to Smart Grid. 
- **Types of system faults**: Majority of the power system elements are exposed to the environment such as substations, transmission lines, etc. that are sitting outside. As a result, they are exposed to the elements of weather. Electrons have to be confined to a conductor. As soon as they aren't, it creates a fault. So for eg. if lightning strikes a line, it connects to the ground, so flow of electrons goes to the ground. A fault. If two conductors get connected instead, that's also a fault. You have a conductor and an insulator above the line. If the insulator gets contaminated then that's a fault because the electrons are not confined to the conductor itself. Animals can get into the distribution substations and cause a fault. Human error could occur, eg. maintenance tech leaves a tool where it shouldn't be, and when system turns on, there is a fault. Trees falling on lines. Trees may touch conductors when they sag on really hot days causing a fault. Conductors and insulators can break down faster due to age and elements combined.
- **What happens during a fault**: Phase A, b, c, and neutral are shown in the diagram slide titled "Voltages and currents during faults". The graph starts by showing normal current close to 200 amps. As soon as lightning strikes, phase B current goes close to 4500 amps. A and C doesn't change. Neutral goes up in the opposite direction because everything has to add to zero. So it goes down to around 4500. There is a decaying DC component in phase B because the peaks are going down over time after the spike. So the magnitude goes up and there is a decaying DC component in phase B. There may be some high frequency components there because of the fluctuating waves. Majority of it is 60hz. Same thing happens with neutral current because it is the opposite.
- Then after 2.5 cycles of 60hz . One cycle is 1/60 seconds or 16.67ms. Therefore 16.67 times 2.5 so around 40ms is how long phase B was disconnected. The protection device detected the lightning strike within that time, and fixed the issue as shown in the graph. So it has to be extremely fast, including the breaker time. The device has to detect the issue and give a command to the breaker to open which phase is out of sync. So the device should be a few ms only so that you can account the time required to open the breaker. Some breakers can take up to 2.5 to 3 cycles to open, so the device has to be very quick. Speed is very important.
- Speed and accuracy in DSP are opposite to each other. If you want accurate result, it will be very slow. If you want fast results it won't be as accurate. This is why this area of science is called Art and Science, where getting the right balance is the Art part. The normal current was about 200 ampere. During the strike it went up to around 1400 ampere during the strike. So the range of measuring amperes should be 0 to 5000 amperes. This is a challenge because you have to be able to measure this dynamic range, and be accurate through this range to maintain that.
- **What happens to the voltage during the fault**: Looking at the same fault as previous slide. The voltage goes down for phase B, but the other two volts are consistent. Notice how there is a lot of notice, which is due to the high frequency components of a lightning strike. Voltage is generally less of a problem to measure because the range is much smaller. It goes down, but not by like 20 times which the current does. So when the fault happens and when it clears (breaker kicks in) there is noise.
- Main purpose to develop algorithms is to extract certain frequency components from waveforms. Sometimes we want to extract harmonics. It depends on the application. Same for voltage, certain components will extracted.
- Requirements for protection is speed, selectivity
	- Selectivity in the sense that when a fault happens anywhere in the system, we measure the current only at that particular line, but current in other lines also go up, because generators are generating that current, which supply current to other lines in the area. So the protection device has to selectively target the line to be remove/isolated so that it isn't affecting other lines unnecessarily.
	- Speed is important because if the fault stays for too long, lines could burn, transformers could burn up, other damage could occur. The system also becomes unstable if the fault is left beyond the critical clearing time (every system has this) the system becomes unstable. NERC will then kick you out because you are not able to remain connected to the system. The large amounts of current will create so much mechanical force that it will structurally destroy wires etc.
- Relays will continuously measure the voltage and current and might be placed on either side of a transmission line etc. Current transformers are used to lower the current, generally to 1amperes or 5 amperes which is the nominal value. Similarly, if the voltage is 500, then it will be lowered to 140 volt. The scale goes down but everything else stays the same, the shape of the waves, etc. and that is where it will sit. So a current spike to 4500 might get reduce by a scale of 50 to 1. Relays have become a fundamental part of smart grid because it is already measuring voltages and currents which smart grid needs at every point in the system. Relays have memory too, so it can store the values, which is how we have the graph in the lecture notes. It stored the data during the lightning strike which became useful for analysis, which is rare since faults rarely happen. Relays monitor the system at every 1/4800 seconds. 
- The device is split up into different zones of protection. Line protection zone, busbar protection. Generator protection. Motor protection. The devices are responsible for protecting that zone. The algorithm only measures the activities in that area, so that that device knows that when something goes wrong, it's either happening in that area or somewhere else.
- If a device becomes more secure, it becomes less dependable. If it becomes less secure, it becomes more dependable.
- **Evolution of relays**: Fuse sees overcurrent and blows if it goes over. Then Bi-metallic doesn't blow but opens up instead. Then Electromechanical relays used the principals of electrical systems which would operate depending on mechanical principals based on how it was applied. Then static relays which are mainly operational amplifiers which didn't last very long because they didn't have much reliability. Reliability has to be very high because faults happen very rarely, but when it happens, it has to be extremely reliable when it is needed. Then digital relays were developed which used digital circuits. Then numerical relays (microprocessor) which had communication, memory, self supervision. As we started moving towards smart grid they started adding intelligent functions, non-fault monitoring, integration and automation, flexibility. Next level is IED and more.
- Prodar 70 system was the size of a room because programming was fairly new at the time, but the computations and computing they did was very complex. It was a research project, and wasn't a commercial product to show the capabilities. Even if they wanted to make a  commercial product they couldn't due to the massive size of the computer. Based on analyzing the voltage and current they could determine the exact location of the fault using complex algorithms. These features are very common now where it can self monitor and report that something is going on. Back then it was a very expensive experiment which lead the way to what we have these days. it was a great proof of concept, and there were other experiments too after that.
- DSP methods (voice processing, communication, etc.) have vast amounts of time available, but we have extremely limited time for fault detection, so the methods are different from DSP. Also the data available is very limited compared to the traditional DSP methods which have vast amounts of data available like voice samples etc. A lot of computation is involved and phasors are involved. 
- Discrete Fourier transform was used for a long time and is still the most widely used phasor technique but better techniques are available these days.
- Time domain methods don't calculate the phasors but provide the same results, which is good because phasor calculation can be very complicated or time consuming. 
- Measuring frequency in a very short time is even more challenging than measuring phasers.
- Back then they couldn't even do simple calculations like multiplication using processors so they had to use things like True RMS values etc. In the mid 80's simple microprocessors were invented which allowed for a bit more complexity.
- A lot of startup companies fail because no one wants a product that doesn't save money. The cost is too high, or the innovation is ahead of it's time. That's why microprocessor relays became popular, due to the cost savings, functionality, and delivery time. Spares had to be kept in the past because delivery times could take up to a year. With microprocessor relays, it was easy to manufacture and ship within a few weeks time, so no inventory needed.
- General purpose or universal relays are being developed where the hardware is common.
- You can now put many functionalities in one unit, where in the past it had to be separated into different units. These are called multifunctional products. Instead of wiring ten units, you're wiring only one. These save space and burden (3 ampere at 125 vdc vs 100mA at 124 vdc). 
- Since relays sit in one spot constantly monitoring the zone without communicating externally, it was hard to tell whether the relays had died. It was very expensive to do maintenance work to check if it working or not, and also deciding how often it had to be maintained was difficult to determine. the newer relays report failures instantly, self calibrate, no maintenance required due to self checking, and repairing is extremely easy since the system is modular and can be easily swapped out.
- 